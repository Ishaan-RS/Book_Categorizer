{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Physics</th>\n",
       "      <th>Chemistry</th>\n",
       "      <th>Maths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Cartoon Guide to Chemistry, Larry Gonick</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elemental: How the Periodic Table Can Now Expl...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Mathematician's Lament: How School Cheats Us...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the right stuff, tom wolfe</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>introduction to electrodynamics, david j. grif...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Physics  Chemistry  \\\n",
       "0       The Cartoon Guide to Chemistry, Larry Gonick        0          1   \n",
       "1  Elemental: How the Periodic Table Can Now Expl...        0          1   \n",
       "2  A Mathematician's Lament: How School Cheats Us...        0          0   \n",
       "3                         the right stuff, tom wolfe        1          0   \n",
       "4  introduction to electrodynamics, david j. grif...        1          0   \n",
       "\n",
       "   Maths  \n",
       "0      0  \n",
       "1      0  \n",
       "2      1  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"PATH_OF_DATASET_HERE\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USING TEXT VECTORIZATION TO CREATE A TOKEN DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization\n",
    "x = df[\"Text\"]\n",
    "y = df[df.columns[1:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 50000\n",
    "vectorizer = TextVectorization(max_tokens = max_words, output_sequence_length = 100, output_mode = \"int\")\n",
    "\n",
    "vectorizer.adapt(x.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '[UNK]',\n",
       " 'the',\n",
       " 'of',\n",
       " 'a',\n",
       " 'and',\n",
       " 'to',\n",
       " 'physics',\n",
       " 'in',\n",
       " 'science',\n",
       " 'mathematical',\n",
       " 'how',\n",
       " 'history',\n",
       " 'goodreads',\n",
       " 'chemistry',\n",
       " 'author',\n",
       " 'mathematics',\n",
       " 'richard',\n",
       " 'for',\n",
       " 'universe',\n",
       " 'from',\n",
       " 'david',\n",
       " 'quantum',\n",
       " 'new',\n",
       " 'math',\n",
       " 'feynman',\n",
       " 'story',\n",
       " 'stephen',\n",
       " 'time',\n",
       " 'paul',\n",
       " 'on',\n",
       " 'genius',\n",
       " 'world',\n",
       " 'steven',\n",
       " 'p',\n",
       " 'john',\n",
       " 'j',\n",
       " 'introduction',\n",
       " 'hawking',\n",
       " 'that',\n",
       " 'stewart',\n",
       " 's',\n",
       " 'reality',\n",
       " 'man',\n",
       " 'ian',\n",
       " 'book',\n",
       " 'an',\n",
       " 'with',\n",
       " 'william',\n",
       " 'who',\n",
       " 'martin',\n",
       " 'm',\n",
       " 'life',\n",
       " 'is',\n",
       " 'infinity',\n",
       " 'everything',\n",
       " 'brief',\n",
       " 'through',\n",
       " 'theory',\n",
       " 'simon',\n",
       " 'scientific',\n",
       " 'robert',\n",
       " 'our',\n",
       " 'one',\n",
       " 'mechanics',\n",
       " 'h',\n",
       " 'elements',\n",
       " 'changed',\n",
       " 'at',\n",
       " 'worlds',\n",
       " 'what',\n",
       " 'us',\n",
       " 'things',\n",
       " 'strogatz',\n",
       " 'search',\n",
       " 'roger',\n",
       " 'r',\n",
       " 'penrose',\n",
       " 'numbers',\n",
       " 'number',\n",
       " 'molecules',\n",
       " 'modern',\n",
       " 'love',\n",
       " 'leonard',\n",
       " 'james',\n",
       " 'hidden',\n",
       " 'greatest',\n",
       " 'd',\n",
       " 'chemical',\n",
       " 'carroll',\n",
       " 'c',\n",
       " 'brian',\n",
       " 'birth',\n",
       " 'big',\n",
       " 'why',\n",
       " 'w',\n",
       " 'two',\n",
       " 'truth',\n",
       " 'true',\n",
       " 'tim',\n",
       " 'thomas',\n",
       " 'solved',\n",
       " 'smolin',\n",
       " 'singh',\n",
       " 'short',\n",
       " 'sean',\n",
       " 'rovelli',\n",
       " 'roald',\n",
       " 'problem',\n",
       " 'philosophy',\n",
       " 'other',\n",
       " 'only',\n",
       " 'nicholas',\n",
       " 'most',\n",
       " 'mind',\n",
       " 'many',\n",
       " 'lee',\n",
       " 'lectures',\n",
       " 'lawrence',\n",
       " 'krauss',\n",
       " 'invention',\n",
       " 'ingredients',\n",
       " 'i',\n",
       " 'hoffmann',\n",
       " 'hager',\n",
       " 'greene',\n",
       " 'god',\n",
       " 'george',\n",
       " 'general',\n",
       " 'everyday',\n",
       " 'erdos',\n",
       " 'einstein',\n",
       " 'dunham',\n",
       " 'chaos',\n",
       " 'carlo',\n",
       " 'carl',\n",
       " 'by',\n",
       " 'art',\n",
       " 'albert',\n",
       " 'air',\n",
       " 'age',\n",
       " 'youre',\n",
       " 'your',\n",
       " 'young',\n",
       " 'you',\n",
       " 'way',\n",
       " 'was',\n",
       " 'walter',\n",
       " 'visual',\n",
       " 'very',\n",
       " 'verma',\n",
       " 'unknown',\n",
       " 'uncle',\n",
       " 'tour',\n",
       " 'timothy',\n",
       " 'three',\n",
       " 'thorne',\n",
       " 'theorems',\n",
       " 'theodore',\n",
       " 'tegmark',\n",
       " 'taleb',\n",
       " 'tale',\n",
       " 'table',\n",
       " 'susskind',\n",
       " 'surely',\n",
       " 'strange',\n",
       " 'steve',\n",
       " 'so',\n",
       " 'slater',\n",
       " 'six',\n",
       " 'shulgin',\n",
       " 'shankar',\n",
       " 'scientists',\n",
       " 'sagan',\n",
       " 'road',\n",
       " 'revolution',\n",
       " 'relativity',\n",
       " 'real',\n",
       " 'randomness',\n",
       " 'randall',\n",
       " 'quellen',\n",
       " 'publishing',\n",
       " 'professor',\n",
       " 'problems',\n",
       " 'principles',\n",
       " 'poundstone',\n",
       " 'pieces',\n",
       " 'philip',\n",
       " 'periodic',\n",
       " 'particle',\n",
       " 'parallel',\n",
       " 'out',\n",
       " 'order',\n",
       " 'obsession',\n",
       " 'nobel',\n",
       " 'nearly',\n",
       " 'nature',\n",
       " 'nassim',\n",
       " 'nahin',\n",
       " 'my',\n",
       " 'mulliken',\n",
       " 'mr',\n",
       " 'more',\n",
       " 'molecular',\n",
       " 'mlodinow',\n",
       " 'minds',\n",
       " 'michio',\n",
       " 'michael',\n",
       " 'men',\n",
       " 'medicine',\n",
       " 'max',\n",
       " 'mathematicians',\n",
       " 'mario',\n",
       " 'making',\n",
       " 'loved',\n",
       " 'livio',\n",
       " 'lithium',\n",
       " 'lines',\n",
       " 'limits',\n",
       " 'law',\n",
       " 'language',\n",
       " 'lane',\n",
       " 'l',\n",
       " 'kuhn',\n",
       " 'knew',\n",
       " 'kip',\n",
       " 'kenneth',\n",
       " 'karl',\n",
       " 'kaku',\n",
       " 'journey',\n",
       " 'joking',\n",
       " 'its',\n",
       " 'it',\n",
       " 'isaac',\n",
       " 'impact',\n",
       " 'imaginary',\n",
       " 'ibn',\n",
       " 'holzner',\n",
       " 'hoffman',\n",
       " 'halliday',\n",
       " 'guide',\n",
       " 'griffiths',\n",
       " 'great',\n",
       " 'gowers',\n",
       " 'geometry',\n",
       " 'gardner',\n",
       " 'gamow',\n",
       " 'fundamentals',\n",
       " 'fundamental',\n",
       " 'foundation',\n",
       " 'formula',\n",
       " 'form',\n",
       " 'food',\n",
       " 'flatland',\n",
       " 'field',\n",
       " 'fascinating',\n",
       " 'fabric',\n",
       " 'f',\n",
       " 'exploration',\n",
       " 'eulers',\n",
       " 'euclids',\n",
       " 'euclid',\n",
       " 'emperors',\n",
       " 'elementary',\n",
       " 'edward',\n",
       " 'editor',\n",
       " 'e',\n",
       " 'dummies',\n",
       " 'drugs',\n",
       " 'drug',\n",
       " 'dreams',\n",
       " 'dr',\n",
       " 'doxiadis',\n",
       " 'douglas',\n",
       " 'do',\n",
       " 'discovered',\n",
       " 'dimension',\n",
       " 'deutsch',\n",
       " 'derbyshire',\n",
       " 'dangerous',\n",
       " 'crystallography',\n",
       " 'cosmos',\n",
       " 'cooking',\n",
       " 'contributor',\n",
       " 'concerning',\n",
       " 'concepts',\n",
       " 'computer',\n",
       " 'color',\n",
       " 'clawson',\n",
       " 'chemists',\n",
       " 'character',\n",
       " 'cathy',\n",
       " 'can',\n",
       " 'calvin',\n",
       " 'calculus',\n",
       " 'but',\n",
       " 'brown',\n",
       " 'breakthrough',\n",
       " 'bomb',\n",
       " 'black',\n",
       " 'biology',\n",
       " 'biography',\n",
       " 'billions',\n",
       " 'basic',\n",
       " 'astrobiology',\n",
       " 'astonishing',\n",
       " 'asimov',\n",
       " 'apostolos',\n",
       " 'am',\n",
       " 'alexander',\n",
       " 'alchemy',\n",
       " 'alan',\n",
       " 'adventures',\n",
       " '5',\n",
       " '17',\n",
       " '1',\n",
       " 'zones',\n",
       " 'zero',\n",
       " 'zaidan',\n",
       " 'york',\n",
       " 'y',\n",
       " 'x',\n",
       " 'wrinkle',\n",
       " 'wothers',\n",
       " 'wonderland',\n",
       " 'wonder',\n",
       " 'wolfram',\n",
       " 'wolfe',\n",
       " 'wolf',\n",
       " 'window',\n",
       " 'wilson',\n",
       " 'when',\n",
       " 'westhoff',\n",
       " 'west',\n",
       " 'were',\n",
       " 'weird',\n",
       " 'weinberg',\n",
       " 'weapons',\n",
       " 'we',\n",
       " 'wave',\n",
       " 'watson',\n",
       " 'wars',\n",
       " 'warps',\n",
       " 'wanted',\n",
       " 'walters',\n",
       " 'wallace',\n",
       " 'walker',\n",
       " 'walk',\n",
       " 'von',\n",
       " 'vol',\n",
       " 'vo',\n",
       " 'view',\n",
       " 'unsolved',\n",
       " 'unraveling',\n",
       " 'unlock',\n",
       " 'university',\n",
       " 'united',\n",
       " 'understanding',\n",
       " 'under',\n",
       " 'ultimate',\n",
       " 'tycoon',\n",
       " 'turro',\n",
       " 'turing',\n",
       " 'tungsten',\n",
       " 'trouble',\n",
       " 'transcend',\n",
       " 'tragedy',\n",
       " 'traces',\n",
       " 'toxic',\n",
       " 'topologydavid',\n",
       " 'toothpaste',\n",
       " 'too',\n",
       " 'tony',\n",
       " 'tom',\n",
       " 'tobias',\n",
       " 'tips',\n",
       " 'tihkal',\n",
       " 'threeinfinity',\n",
       " 'threatens',\n",
       " 'thinking',\n",
       " 'thing',\n",
       " 'theres',\n",
       " 'theoretical',\n",
       " 'theorem',\n",
       " 'thats',\n",
       " 'terror',\n",
       " 'ten',\n",
       " 'temple',\n",
       " 'technological',\n",
       " 'tales',\n",
       " 'tahan',\n",
       " 'system',\n",
       " 'synthesis',\n",
       " 'sync',\n",
       " 'symmetry',\n",
       " 'sylvia',\n",
       " 'swan',\n",
       " 'survive',\n",
       " 'surprising',\n",
       " 'surfaces',\n",
       " 'superbatteries',\n",
       " 'suffice',\n",
       " 'suffer',\n",
       " 'stuff',\n",
       " 'structures',\n",
       " 'stone',\n",
       " 'still',\n",
       " 'stern',\n",
       " 'sterling',\n",
       " 'steps',\n",
       " 'stephenson',\n",
       " 'statistics',\n",
       " 'states',\n",
       " 'square',\n",
       " 'spoon',\n",
       " 'spontaneous',\n",
       " 'speculations',\n",
       " 'special',\n",
       " 'sparked',\n",
       " 'spacesuits',\n",
       " 'space',\n",
       " 'sorcery',\n",
       " 'something',\n",
       " 'some',\n",
       " 'solve',\n",
       " 'solutions',\n",
       " 'solidstate',\n",
       " 'solids',\n",
       " 'socrates',\n",
       " 'society',\n",
       " 'sobel',\n",
       " 'snowflakes',\n",
       " 'singularity',\n",
       " 'since',\n",
       " 'silver',\n",
       " 'silicon',\n",
       " 'signal',\n",
       " 'shumeet',\n",
       " 'shouldnt',\n",
       " 'shaw',\n",
       " 'shaped',\n",
       " 'seven',\n",
       " 'seth',\n",
       " 'selected',\n",
       " 'seife',\n",
       " 'seems',\n",
       " 'secrets',\n",
       " 'secret',\n",
       " 'secrecy',\n",
       " 'searching',\n",
       " 'scott',\n",
       " 'scientist',\n",
       " 'schwarcz',\n",
       " 'school',\n",
       " 'schlesinger',\n",
       " 'schechter',\n",
       " 'scale',\n",
       " 'sautoy',\n",
       " 'saunders',\n",
       " 'sam',\n",
       " 'sacrifice',\n",
       " 'sacks',\n",
       " 'sabine',\n",
       " 'rules',\n",
       " 'root',\n",
       " 'ronald',\n",
       " 'romantic',\n",
       " 'romance',\n",
       " 'role',\n",
       " 'rogue',\n",
       " 'rocket',\n",
       " 'robin',\n",
       " 'roads',\n",
       " 'rise',\n",
       " 'rigor',\n",
       " 'right',\n",
       " 'riemann',\n",
       " 'richeson',\n",
       " 'rhodes',\n",
       " 'reviel',\n",
       " 'revealing',\n",
       " 'rees',\n",
       " 'reborn',\n",
       " 'reason',\n",
       " 'reactions',\n",
       " 'ray',\n",
       " 'ratio',\n",
       " 'ramanujan',\n",
       " 'ralph',\n",
       " 'quintet',\n",
       " 'questions',\n",
       " 'quest',\n",
       " 'quantity',\n",
       " 'qed',\n",
       " 'pythagoras',\n",
       " 'puzzles',\n",
       " 'puzzle',\n",
       " 'put',\n",
       " 'pursuit',\n",
       " 'purcell',\n",
       " 'proofs',\n",
       " 'products',\n",
       " 'probably',\n",
       " 'prisoners',\n",
       " 'principia',\n",
       " 'princeton',\n",
       " 'primes',\n",
       " 'prime',\n",
       " 'presidents',\n",
       " 'predictions',\n",
       " 'prayer',\n",
       " 'pratt',\n",
       " 'powers',\n",
       " 'power',\n",
       " 'powders',\n",
       " 'portraits',\n",
       " 'portable',\n",
       " 'polyhedron',\n",
       " 'poisoners',\n",
       " 'plutonium',\n",
       " 'pleasure',\n",
       " 'play',\n",
       " 'plaxco',\n",
       " 'plants',\n",
       " 'pills',\n",
       " 'pihkal',\n",
       " 'picture',\n",
       " 'pickover',\n",
       " 'physical',\n",
       " 'photochemistry',\n",
       " 'phi',\n",
       " 'petros',\n",
       " 'petr',\n",
       " 'peter',\n",
       " 'perfect',\n",
       " 'percent',\n",
       " 'penny',\n",
       " 'paulos',\n",
       " 'pauling',\n",
       " 'patrick',\n",
       " 'past',\n",
       " 'parrots',\n",
       " 'parker',\n",
       " 'paradox',\n",
       " 'papers',\n",
       " 'panek',\n",
       " 'othen',\n",
       " 'optics',\n",
       " 'opioid',\n",
       " 'open',\n",
       " 'oneil',\n",
       " 'once',\n",
       " 'olympian',\n",
       " 'oliver',\n",
       " 'ocean',\n",
       " 'nutshell',\n",
       " 'now',\n",
       " 'novel',\n",
       " 'notsoeasy',\n",
       " 'nothing',\n",
       " 'not',\n",
       " 'noschese',\n",
       " 'nonlinear',\n",
       " 'noise',\n",
       " 'nicolaou',\n",
       " 'nick',\n",
       " 'newton',\n",
       " 'neumann',\n",
       " 'netz',\n",
       " 'near',\n",
       " 'neal',\n",
       " 'nazi',\n",
       " 'natures',\n",
       " 'natural',\n",
       " 'nate',\n",
       " 'nassau',\n",
       " 'nasar',\n",
       " 'napoleons',\n",
       " 'named',\n",
       " 'mystery',\n",
       " 'mysteries',\n",
       " 'music',\n",
       " 'murder',\n",
       " 'munroe',\n",
       " 'muller',\n",
       " 'much',\n",
       " 'morin',\n",
       " 'monsters',\n",
       " 'mohr',\n",
       " 'mismeasure',\n",
       " 'miracle',\n",
       " 'minus',\n",
       " 'minimum',\n",
       " 'miners',\n",
       " 'milestones',\n",
       " 'microscope',\n",
       " 'methods',\n",
       " 'medieval',\n",
       " 'measure',\n",
       " 'mcsween',\n",
       " 'mcgee',\n",
       " 'may',\n",
       " 'maudlin',\n",
       " 'matt',\n",
       " 'mathematician',\n",
       " 'materials',\n",
       " 'masha',\n",
       " 'markets',\n",
       " 'mark',\n",
       " 'marcus',\n",
       " 'map',\n",
       " 'maor',\n",
       " 'mann',\n",
       " 'manjit',\n",
       " 'malba',\n",
       " 'makers',\n",
       " 'make',\n",
       " 'magnus',\n",
       " 'magnetism',\n",
       " 'magic',\n",
       " 'madness',\n",
       " 'madeleine',\n",
       " 'mad',\n",
       " 'macdougall',\n",
       " 'mac',\n",
       " 'lost',\n",
       " 'lore',\n",
       " 'loop',\n",
       " 'looking',\n",
       " 'longitude',\n",
       " 'lone',\n",
       " 'logicomix',\n",
       " 'lockhart',\n",
       " 'lives',\n",
       " 'linus',\n",
       " 'lindley',\n",
       " 'lilac',\n",
       " 'like',\n",
       " 'lightning',\n",
       " 'lie',\n",
       " 'libbrecht',\n",
       " 'lewis',\n",
       " 'lewin',\n",
       " 'letters',\n",
       " 'lessons',\n",
       " 'lerner',\n",
       " 'leon',\n",
       " 'lengle',\n",
       " 'lederman',\n",
       " 'leavitt',\n",
       " 'learn',\n",
       " 'le',\n",
       " 'laws',\n",
       " 'lavoisier',\n",
       " 'lauren',\n",
       " 'larry',\n",
       " 'lament',\n",
       " 'lambert',\n",
       " 'labyrinths',\n",
       " 'labs',\n",
       " 'kurzweil',\n",
       " 'kurt',\n",
       " 'kurson',\n",
       " 'kumar',\n",
       " 'krotov',\n",
       " 'krane',\n",
       " 'known',\n",
       " 'knowledge',\n",
       " 'know',\n",
       " 'knight',\n",
       " 'kleppner',\n",
       " 'kitchen',\n",
       " 'kind',\n",
       " 'kevin',\n",
       " 'kelvin',\n",
       " 'kean',\n",
       " 'kc',\n",
       " 'kanigel',\n",
       " 'kalid',\n",
       " 'jupiters',\n",
       " 'jungle',\n",
       " 'js',\n",
       " 'jr',\n",
       " 'joy',\n",
       " 'journeys',\n",
       " 'joseph',\n",
       " 'jokes',\n",
       " 'johnson',\n",
       " 'joe',\n",
       " 'jewish',\n",
       " 'jeremy',\n",
       " 'jazz',\n",
       " 'jay',\n",
       " 'jason',\n",
       " 'jan',\n",
       " 'jacobs',\n",
       " 'irodov',\n",
       " 'intuition',\n",
       " 'intriguing',\n",
       " 'interstellar',\n",
       " 'integers',\n",
       " 'innumeracy',\n",
       " 'infinite',\n",
       " 'inequality',\n",
       " 'increases',\n",
       " 'inc',\n",
       " 'improbable',\n",
       " 'impossible',\n",
       " 'impossibility',\n",
       " 'imaginative',\n",
       " 'imagination',\n",
       " 'illustrated',\n",
       " 'ills',\n",
       " 'illiteracy',\n",
       " 'ideas',\n",
       " 'idea',\n",
       " 'hyperspace',\n",
       " 'humans',\n",
       " 'human',\n",
       " 'hugh',\n",
       " 'huff',\n",
       " 'household',\n",
       " 'hossenfelder',\n",
       " 'hospitals',\n",
       " 'hoshino',\n",
       " 'horizons',\n",
       " 'home',\n",
       " 'holmes',\n",
       " 'holes',\n",
       " 'hofstadter',\n",
       " 'hitler',\n",
       " 'his',\n",
       " 'hilbert',\n",
       " 'highly',\n",
       " 'hibbs',\n",
       " 'hey',\n",
       " 'hexaflexagons',\n",
       " 'heroic',\n",
       " 'heres',\n",
       " 'here',\n",
       " 'henry',\n",
       " 'heart',\n",
       " 'hazen',\n",
       " 'haytham',\n",
       " 'have',\n",
       " 'harry',\n",
       " 'harold',\n",
       " 'hardy',\n",
       " 'hans',\n",
       " 'handbook',\n",
       " 'haldane',\n",
       " 'gullberg',\n",
       " 'guided',\n",
       " 'guedj',\n",
       " 'greg',\n",
       " 'gray',\n",
       " 'gravity',\n",
       " 'grand',\n",
       " 'graham',\n",
       " 'gould',\n",
       " 'gottlieb',\n",
       " 'goodman',\n",
       " 'gonick',\n",
       " 'golden',\n",
       " 'goldbachs',\n",
       " 'gold',\n",
       " 'gleick',\n",
       " 'glazer',\n",
       " 'gh',\n",
       " 'gessen',\n",
       " 'geometrical',\n",
       " 'geoffrey',\n",
       " 'generation',\n",
       " 'gem',\n",
       " 'gas',\n",
       " 'game',\n",
       " 'gabrielle',\n",
       " 'future',\n",
       " 'function',\n",
       " 'fueled',\n",
       " 'front',\n",
       " 'frenkel',\n",
       " 'frank',\n",
       " 'frailty',\n",
       " 'fourth',\n",
       " 'four',\n",
       " 'foster',\n",
       " 'forged',\n",
       " 'foreword',\n",
       " 'forensic',\n",
       " 'fooled',\n",
       " 'fletcher',\n",
       " 'flatterland',\n",
       " 'first',\n",
       " 'finding',\n",
       " 'final',\n",
       " 'fifth',\n",
       " 'fifteen',\n",
       " 'feymans',\n",
       " 'fermats',\n",
       " 'fentanyl',\n",
       " 'fed',\n",
       " 'features',\n",
       " 'faraday',\n",
       " 'faith',\n",
       " 'failbut',\n",
       " 'facts',\n",
       " 'fabulous',\n",
       " 'extreme',\n",
       " 'extended',\n",
       " 'exposure',\n",
       " 'explainer',\n",
       " 'explained',\n",
       " 'explain',\n",
       " 'experiments',\n",
       " 'experience',\n",
       " 'exhibition',\n",
       " 'excursion',\n",
       " 'everyone',\n",
       " 'every',\n",
       " 'ettlinger',\n",
       " 'essentials',\n",
       " 'essence',\n",
       " 'eric',\n",
       " 'equations',\n",
       " 'equation',\n",
       " 'epstein',\n",
       " 'epidemic',\n",
       " 'epic',\n",
       " 'enzensberger',\n",
       " 'enigma',\n",
       " 'engineers',\n",
       " 'engineering',\n",
       " 'end',\n",
       " 'emsley',\n",
       " 'emeritus',\n",
       " 'emerging',\n",
       " 'eli',\n",
       " 'elemental',\n",
       " 'element',\n",
       " 'elegant',\n",
       " 'electrodynamics',\n",
       " 'electricity',\n",
       " 'electric',\n",
       " 'egypt',\n",
       " 'edwin',\n",
       " 'education',\n",
       " 'economy',\n",
       " 'eberhart',\n",
       " 'easy',\n",
       " 'dynamics',\n",
       " 'dung',\n",
       " 'du',\n",
       " 'drunkards',\n",
       " 'dragons',\n",
       " 'doug',\n",
       " 'doors',\n",
       " 'doomed',\n",
       " 'dont',\n",
       " 'donkey',\n",
       " 'donald',\n",
       " 'does',\n",
       " 'doctors',\n",
       " 'doctor',\n",
       " 'dna',\n",
       " 'diversions',\n",
       " 'discovery',\n",
       " 'disappearing',\n",
       " 'dimensions',\n",
       " 'dilemma',\n",
       " 'dice',\n",
       " 'diamond',\n",
       " 'devil',\n",
       " 'destruction',\n",
       " 'design',\n",
       " 'denis',\n",
       " 'demon',\n",
       " 'democritus',\n",
       " 'democracy',\n",
       " 'degrees',\n",
       " 'deeply',\n",
       " 'deborah',\n",
       " 'deadliest',\n",
       " 'davis',\n",
       " 'davenport',\n",
       " 'dava',\n",
       " 'data',\n",
       " 'darrell',\n",
       " 'dantzig',\n",
       " 'daniel',\n",
       " 'dalton',\n",
       " 'dale',\n",
       " 'cut',\n",
       " 'curious',\n",
       " 'cures',\n",
       " 'cummings',\n",
       " 'culinary',\n",
       " 'crystals',\n",
       " 'cryptonomicon',\n",
       " 'cryptography',\n",
       " 'crumbles',\n",
       " 'creating',\n",
       " 'created',\n",
       " 'cox',\n",
       " 'couteur',\n",
       " 'courant',\n",
       " 'counted',\n",
       " 'couldnt',\n",
       " 'cosmochemistry',\n",
       " 'cookie',\n",
       " 'conundrums',\n",
       " 'continuation',\n",
       " 'consequences',\n",
       " 'conjecture',\n",
       " 'concrete',\n",
       " 'computing',\n",
       " 'computers',\n",
       " 'complete',\n",
       " 'companion',\n",
       " 'compact',\n",
       " 'commentaries',\n",
       " 'comes',\n",
       " 'colossal',\n",
       " 'colors',\n",
       " 'collection',\n",
       " 'codex',\n",
       " 'code',\n",
       " 'cobb',\n",
       " 'clocks',\n",
       " 'clifford',\n",
       " 'classical',\n",
       " 'class',\n",
       " 'clarke',\n",
       " 'christian',\n",
       " 'cheats',\n",
       " 'chasing',\n",
       " 'charles',\n",
       " 'chance',\n",
       " 'century',\n",
       " 'central',\n",
       " 'causes',\n",
       " 'cartoon',\n",
       " 'cars',\n",
       " 'candle',\n",
       " 'canaries',\n",
       " 'cake',\n",
       " 'buttons',\n",
       " 'buerger',\n",
       " 'bryson',\n",
       " 'bruce',\n",
       " 'briefer',\n",
       " 'breakthroughs',\n",
       " 'break',\n",
       " 'brain',\n",
       " 'bottled',\n",
       " 'bonding',\n",
       " 'blum',\n",
       " 'blue',\n",
       " 'blood',\n",
       " 'bill',\n",
       " 'beyond',\n",
       " 'better',\n",
       " 'bernstein',\n",
       " 'bernhard',\n",
       " 'berlinski',\n",
       " 'bends',\n",
       " 'ben',\n",
       " 'bellos',\n",
       " 'bell',\n",
       " 'beginning',\n",
       " 'beginners',\n",
       " 'beckmann',\n",
       " 'becker',\n",
       " 'beauty',\n",
       " 'beautiful',\n",
       " 'be',\n",
       " 'battlefield',\n",
       " 'battle',\n",
       " 'battery',\n",
       " 'barrow',\n",
       " 'barons',\n",
       " 'bardi',\n",
       " 'bang',\n",
       " 'baluja',\n",
       " 'ball',\n",
       " 'b',\n",
       " 'azad',\n",
       " 'attacks',\n",
       " 'atomic',\n",
       " 'atom',\n",
       " 'atmosphere',\n",
       " 'astronomy',\n",
       " 'astrochemistry',\n",
       " 'are',\n",
       " 'archimedes',\n",
       " 'archaeology',\n",
       " 'approach',\n",
       " 'applications',\n",
       " 'apology',\n",
       " 'apart',\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_vocabulary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(259, 100), dtype=int64, numpy=\n",
       "array([[  2, 941, 240, ...,   0,   0,   0],\n",
       "       [838,  11,   2, ...,   0,   0,   0],\n",
       "       [  4, 211, 656, ...,   0,   0,   0],\n",
       "       ...,\n",
       "       [  2, 126, 189, ...,   0,   0,   0],\n",
       "       [658,   3, 483, ...,   0,   0,   0],\n",
       "       [  4, 153,   3, ...,   0,   0,   0]], dtype=int64)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_text = vectorizer(x.values)\n",
    "vectorized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DIVIDING THE DATASET INTO BATCHES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(42)\n",
    "dataset = dataset.batch(18)\n",
    "dataset = dataset.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_x, batch_y = dataset.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataset.take(int(len(dataset)*.8))\n",
    "val = dataset.skip(int(len(dataset)*.8)).take(int(len(dataset)*.1))\n",
    "test = dataset.skip(int(len(dataset)*.9)).take(int(len(dataset)*.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[313, 409,   6, ...,   0,   0,   0],\n",
       "        [270,   3,   4, ...,   0,   0,   0],\n",
       "        [861, 126, 521, ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [ 55,   5, 202, ...,   0,   0,   0],\n",
       "        [337,   3,  24, ...,   0,   0,   0],\n",
       "        [121,   4, 148, ...,   0,   0,   0]], dtype=int64),\n",
       " array([[1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0]], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator = train.as_numpy_iterator()\n",
    "train_generator.next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL CREATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dropout, Bidirectional, Dense, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(max_words + 1, 32))\n",
    "\n",
    "model.add(Bidirectional(LSTM(32, activation = \"tanh\")))\n",
    "\n",
    "model.add(Dense(128, activation = \"relu\" ))\n",
    "model.add(Dense(256, activation = \"relu\" ))\n",
    "model.add(Dense(128, activation = \"relu\" ))\n",
    "\n",
    "model.add(Dense(3, activation = \"sigmoid\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = \"BinaryCrossentropy\", optimizer = \"Adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 32)          1600032   \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 64)               16640     \n",
      " l)                                                              \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               8320      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 387       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,691,299\n",
      "Trainable params: 1,691,299\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train, epochs \u001b[39m=\u001b[39;49m \u001b[39m30\u001b[39;49m, validation_data \u001b[39m=\u001b[39;49m val)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\Desktop\\IMP\\Python\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\Desktop\\IMP\\Python\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\Desktop\\IMP\\Python\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\Desktop\\IMP\\Python\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\Desktop\\IMP\\Python\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:980\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    976\u001b[0m     \u001b[39mpass\u001b[39;00m  \u001b[39m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    978\u001b[0m     \u001b[39m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    979\u001b[0m     \u001b[39m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 980\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    981\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    982\u001b[0m   _, _, filtered_flat_args \u001b[39m=\u001b[39m (\n\u001b[0;32m    983\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn\u001b[39m.\u001b[39m_function_spec\u001b[39m.\u001b[39mcanonicalize_function_inputs(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    984\u001b[0m           \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds))\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\Desktop\\IMP\\Python\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\Desktop\\IMP\\Python\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\Desktop\\IMP\\Python\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\Lenovo\\Desktop\\IMP\\Python\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(train, epochs = 30, validation_data = val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m \u001b[39mimport\u001b[39;00m pyplot \u001b[39mas\u001b[39;00m plt\n\u001b[1;32m----> 2\u001b[0m pd\u001b[39m.\u001b[39mDataFrame(history\u001b[39m.\u001b[39mhistory)\u001b[39m.\u001b[39mplot()\n\u001b[0;32m      3\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 485ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.9993548e-01, 9.8624194e-05, 8.0265187e-02]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = test.as_numpy_iterator().next()\n",
    "input_text = vectorizer(\"plane trignometry\")\n",
    "model.predict(np.expand_dims(input_text, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_x, batch_y = test.as_numpy_iterator().next()\n",
    "batch_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.4663765e-05, 1.0543269e-03, 9.9861240e-01],\n",
       "       [1.3585849e-04, 3.5456292e-04, 9.9923778e-01],\n",
       "       [2.0232362e-06, 9.9985731e-01, 2.6752925e-04],\n",
       "       [1.2845477e-06, 9.9990857e-01, 1.6436762e-04],\n",
       "       [1.7855715e-03, 1.1121560e-03, 9.9560320e-01],\n",
       "       [9.9999535e-01, 1.6809247e-08, 2.4936987e-06],\n",
       "       [9.9900836e-01, 9.9628460e-06, 7.6758419e-04],\n",
       "       [2.9607423e-04, 6.9866903e-05, 9.9952602e-01],\n",
       "       [8.7882324e-07, 9.9989438e-01, 2.4390215e-04],\n",
       "       [2.3177240e-07, 9.9997318e-01, 5.3413951e-05],\n",
       "       [2.9501619e-04, 1.0859162e-04, 9.9943560e-01],\n",
       "       [9.1030952e-06, 9.9926013e-01, 1.5368931e-03],\n",
       "       [8.1637586e-03, 3.7958074e-05, 9.9161667e-01],\n",
       "       [1.9665461e-04, 1.7051956e-03, 9.9686915e-01],\n",
       "       [3.0939901e-04, 3.9875173e-04, 9.9886984e-01],\n",
       "       [1.8860259e-04, 4.6725007e-04, 9.9897766e-01],\n",
       "       [2.5351427e-03, 3.5603635e-04, 9.9647731e-01],\n",
       "       [9.9984682e-01, 8.8711840e-07, 1.1332663e-04]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(batch_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEASURING THE PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, CategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = CategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "Precision: 1.0, Recall: 1.0, Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "for batch in test.as_numpy_iterator():\n",
    "    x_true, y_true = batch\n",
    "\n",
    "    yhat = model.predict(x_true)\n",
    "\n",
    "    y_true = y_true.flatten()\n",
    "    yhat = yhat.flatten()\n",
    "\n",
    "    pre.update_state(y_true, yhat)\n",
    "    re.update_state(y_true, yhat)\n",
    "    acc.update_state(y_true, yhat)\n",
    "\n",
    "    print(f'Precision: {float(pre.result())}, Recall: {float(re.result())}, Accuracy: {float(acc.result())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE THE MODEL AS AN .H5 FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"genreclassifier.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LOADING UP THE SAVED MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 523ms/step\n",
      "[0.9906069, 4.25231e-06, 0.008241871]\n",
      "Physics\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"genreclassifier.h5\")\n",
    "input_str = vectorizer(\"Verma\")\n",
    "res = model.predict(np.expand_dims(input_str, 0))\n",
    "Genre = 0\n",
    "l = []\n",
    "for idx, col in enumerate(df.columns[1:]):\n",
    "    l.append(res[0][idx])\n",
    "print(l)\n",
    "m = max(l)\n",
    "subjects = [\"Physics\", \"Chemistry\", \"Maths\"]\n",
    "print(subjects[l.index(m)]) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "22b05ffc4dfdf14572c59801e0327e8ec014292d20458918eb8a31088f0642de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
